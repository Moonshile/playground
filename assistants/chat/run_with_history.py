#!/usr/bin/env python3
"""
raku_infer.py

åŠŸèƒ½ï¼š
1ï¸âƒ£ ä»å‘½ä»¤è¡Œè¯»å–è¾“å…¥æ–‡ä»¶ï¼ˆåŒ…å«æç¤ºè¯ + å¯¹è¯å†å²ï¼‰
2ï¸âƒ£ è‡ªåŠ¨è§£æï¼š
    - ç¬¬ä¸€éƒ¨åˆ† â†’ system message
    - å…¶ä½™å¸¦ user:/assistant: å‰ç¼€çš„å†…å®¹ â†’ å¯¹åº” role
3ï¸âƒ£ è°ƒç”¨ OpenAI GPT-4.1 æ¨¡å‹ç”Ÿæˆå“åº”
4ï¸âƒ£ æ‰“å°ç»“æœå¹¶ä¿å­˜ä¸º <filename>_response.md
"""

import sys
import os
import re
import json
from openai import OpenAI

# ---------- è§£æå‡½æ•° ----------

ROLE_PATTERN = re.compile(r"^(assistant|user)\s*:\s*(.*)$", re.IGNORECASE)
SEPARATOR_PATTERN = re.compile(r"^-{8,}\s*$")  # 8ä¸ªä»¥ä¸ŠçŸ­æ¨ªçº¿è§†ä¸ºåˆ†éš”ç¬¦


def split_header_and_body(text: str):
    """å°†æ–‡ä»¶åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šheaderï¼ˆsystem promptï¼‰å’Œ bodyï¼ˆå¯¹è¯éƒ¨åˆ†ï¼‰"""
    lines = text.splitlines(keepends=True)
    for i, line in enumerate(lines):
        if ROLE_PATTERN.match(line) or SEPARATOR_PATTERN.match(line):
            header = "".join(lines[:i])
            body = "".join(lines[i:])
            return header.strip(), body
    return text.strip(), ""


def parse_role_blocks(body: str):
    """è§£æ user/assistant å—"""
    if not body.strip():
        return []
    lines = body.splitlines()
    messages = []
    current_role = None
    current_lines = []

    def flush():
        nonlocal current_role, current_lines
        if current_role:
            messages.append({
                "role": current_role,
                "content": "\n".join(current_lines).strip()
            })
        current_role = None
        current_lines = []

    for line in lines:
        m = ROLE_PATTERN.match(line)
        if m:
            flush()
            current_role = m.group(1).lower()
            rest = m.group(2) or ""
            current_lines = [rest]
        else:
            if current_role:
                current_lines.append(line)
            elif messages:
                messages[-1]["content"] += "\n" + line
            else:
                current_role = "user"
                current_lines = [line]
    flush()
    return messages


def build_messages(header, parsed):
    messages = []
    if header:
        messages.append({"role": "system", "content": header})
    messages.extend(parsed)
    return messages


# ---------- ä¸»é€»è¾‘ ----------

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python raku_infer.py <conversation_file>")
        sys.exit(1)

    input_path = sys.argv[1]
    if not os.path.exists(input_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        sys.exit(1)

    with open(input_path, "r", encoding="utf-8") as f:
        text = f.read()

    header, body = split_header_and_body(text)
    parsed = parse_role_blocks(body)
    messages = build_messages(header, parsed)

    print("ğŸ§© å·²è§£æè¾“å…¥æ–‡ä»¶:")
    print(f"  System message å­—æ•°: {len(header)}")
    print(f"  å¯¹è¯æ¡æ•°: {len(parsed)}")
    print(f"  æ€»æ¶ˆæ¯æ¡æ•°: {len(messages)}")
    print()

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    if not client:
        print("âŒ è¯·å…ˆè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        sys.exit(1)

    print("ğŸš€ æ­£åœ¨è°ƒç”¨ GPT-4.1ï¼Œè¯·ç¨å€™...\n")

    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=messages,
        temperature=0.3
    )

    reply = response.choices[0].message.content.strip()

    print("âœ… GPT-4.1 å“åº”ç»“æœ:\n")
    print(reply)

    output_path = os.path.splitext(input_path)[0] + "_response.md"
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(reply)
    print(f"\nğŸ’¾ å·²ä¿å­˜ç»“æœåˆ°: {output_path}")


if __name__ == "__main__":
    main()
