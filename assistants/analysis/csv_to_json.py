#!/usr/bin/env python3
"""
csv_to_json.py

åŠŸèƒ½ï¼š
å°† CSV æ ¼å¼çš„èŠå¤©è®°å½•è½¬æ¢ä¸ºæŒ‰ userId èšåˆåçš„ JSON æ–‡ä»¶ã€‚
"""

import sys
import json
import csv
from collections import defaultdict, Counter


def clean_field_name(field_name):
    """
    æ¸…ç†å­—æ®µåï¼Œå»é™¤ BOM å­—ç¬¦å’Œé¦–å°¾ç©ºç™½

    Args:
        field_name (str): åŸå§‹å­—æ®µå

    Returns:
        str: æ¸…ç†åçš„å­—æ®µå
    """
    if not field_name:
        return field_name
    # å»é™¤ BOM å­—ç¬¦ (U+FEFF)
    field_name = field_name.replace('\ufeff', '')
    # å»é™¤é¦–å°¾ç©ºç™½
    return field_name.strip()


def read_csv_chat_records(input_file, encoding='utf-8-sig'):
    """
    è¯»å– CSV èŠå¤©è®°å½•æ–‡ä»¶

    Args:
        input_file (str): è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„
        encoding (str): æ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤: utf-8-sigï¼Œè‡ªåŠ¨å¤„ç† BOMï¼‰

    Returns:
        list: èŠå¤©è®°å½•åˆ—è¡¨
    """
    records = []
    with open(input_file, 'r', encoding=encoding, newline='') as f:
        reader = csv.DictReader(f)
        # æ¸…ç†å­—æ®µåä¸­çš„ BOM å­—ç¬¦
        original_fieldnames = reader.fieldnames
        if original_fieldnames:
            cleaned_fieldnames = [clean_field_name(fn) for fn in original_fieldnames]
            reader.fieldnames = cleaned_fieldnames

        for row in reader:
            # æ¸…ç†æ¯æ¡è®°å½•ä¸­çš„å­—æ®µåï¼ˆå¦‚æœåŸå§‹å­—æ®µåä¸­æœ‰ BOMï¼ŒDictReader å¯èƒ½å·²ç»å¤„ç†ï¼‰
            # ä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œåˆ›å»ºä¸€ä¸ªæ–°å­—å…¸ï¼Œç¡®ä¿å­—æ®µåå¹²å‡€
            cleaned_row = {}
            for key, value in row.items():
                clean_key = clean_field_name(key)
                cleaned_row[clean_key] = value
            records.append(cleaned_row)
    return records


def aggregate_by_user_id(records):
    """
    æŒ‰ userId èšåˆèŠå¤©è®°å½•ï¼Œå¹¶æŒ‰æ—¶é—´é¡ºåºæ’åºæ¯ä¸ªç”¨æˆ·çš„æ¶ˆæ¯

    Args:
        records (list): èŠå¤©è®°å½•åˆ—è¡¨

    Returns:
        dict: æŒ‰ userId èšåˆçš„æ•°æ®ï¼Œæ ¼å¼ä¸º {userId: [messages]}
    """
    aggregated = defaultdict(list)

    for record in records:
        user_id = record.get('userId', '')
        if user_id:
            aggregated[user_id].append(record)

    # è½¬æ¢ä¸ºæ™®é€šå­—å…¸ï¼Œå¹¶æŒ‰æ—¶é—´æ’åºæ¯ä¸ªç”¨æˆ·çš„æ¶ˆæ¯
    result = {}
    for user_id, messages in aggregated.items():
        # æŒ‰ dbctime æ’åºæ¶ˆæ¯ï¼ˆç©ºå€¼æˆ–æ— æ•ˆå€¼æ’åˆ°æœ€åï¼‰
        def sort_key(x):
            dbctime = x.get('dbctime', '')
            if not dbctime or dbctime == 'null':
                return '9999-99-99 99:99:99'  # å°†ç©ºå€¼æ’åˆ°æœ€å
            return dbctime

        sorted_messages = sorted(messages, key=sort_key)
        result[user_id] = sorted_messages

    return result


def save_json(output_file, data, encoding='utf-8', indent=2):
    """
    ä¿å­˜æ•°æ®ä¸º JSON æ–‡ä»¶

    Args:
        output_file (str): è¾“å‡º JSON æ–‡ä»¶è·¯å¾„
        data (dict): è¦ä¿å­˜çš„æ•°æ®
        encoding (str): æ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤: utf-8ï¼‰
        indent (int): JSON ç¼©è¿›ï¼ˆé»˜è®¤: 2ï¼‰
    """
    with open(output_file, 'w', encoding=encoding) as f:
        json.dump(data, f, ensure_ascii=False, indent=indent)


def bucket_message_counts(message_counts):
    """
    å°†æ¶ˆæ¯æ•°é‡åˆ†å¸ƒåˆå¹¶æˆæ¡¶ï¼Œä¾¿äºé˜…è¯»

    Args:
        message_counts (list): æ¯ä¸ªç”¨æˆ·çš„æ¶ˆæ¯æ•°é‡åˆ—è¡¨

    Returns:
        dict: æ¡¶åŒ–çš„åˆ†å¸ƒï¼Œæ ¼å¼ä¸º {bucket_label: user_count}
    """
    buckets = defaultdict(int)

    for count in message_counts:
        if count <= 1:
            buckets["1æ¡"] += 1
        elif count == 2:
            buckets["2æ¡"] += 1
        elif count <= 5:
            buckets["3-5æ¡"] += 1
        elif count <= 10:
            buckets["6-10æ¡"] += 1
        elif count <= 20:
            buckets["11-20æ¡"] += 1
        elif count <= 50:
            buckets["21-50æ¡"] += 1
        elif count <= 100:
            buckets["51-100æ¡"] += 1
        elif count <= 200:
            buckets["101-200æ¡"] += 1
        elif count <= 500:
            buckets["201-500æ¡"] += 1
        else:
            buckets["500+æ¡"] += 1

    return buckets


def print_statistics(aggregated):
    """
    æ‰“å°ç»Ÿè®¡ä¿¡æ¯ï¼šç”¨æˆ·æ•°ã€æ¶ˆæ¯æ€»æ•°ã€æ¶ˆæ¯æ•°é‡åˆ†å¸ƒ

    Args:
        aggregated (dict): æŒ‰ userId èšåˆçš„æ•°æ®
    """
    user_count = len(aggregated)
    total_messages = sum(len(messages) for messages in aggregated.values())

    # è®¡ç®—æ¶ˆæ¯æ•°é‡åˆ†å¸ƒ
    message_counts = [len(messages) for messages in aggregated.values()]

    print("\n" + "="*60)
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print("="*60)
    print(f"ğŸ‘¥ ç”¨æˆ·æ€»æ•°: {user_count}")
    print(f"ğŸ’¬ æ¶ˆæ¯æ€»æ•°: {total_messages}")
    print(f"\nğŸ“ˆ ç”¨æˆ·æ¶ˆæ¯æ•°é‡åˆ†å¸ƒ:")

    if message_counts:
        sorted_counts = sorted(message_counts)

        # è®¡ç®—ä¸­ä½æ•°
        n = len(sorted_counts)
        if n % 2 == 0:
            median = (sorted_counts[n // 2 - 1] + sorted_counts[n // 2]) / 2
        else:
            median = sorted_counts[n // 2]

        print(f"  æœ€å°‘æ¶ˆæ¯æ•°: {min(message_counts)}")
        print(f"  æœ€å¤šæ¶ˆæ¯æ•°: {max(message_counts)}")
        print(f"  å¹³å‡æ¶ˆæ¯æ•°: {total_messages / user_count:.2f}")
        print(f"  ä¸­ä½æ•°æ¶ˆæ¯æ•°: {median:.2f}")
        print(f"\n  åˆ†å¸ƒç»Ÿè®¡:")

        # å°†æ¶ˆæ¯æ•°é‡åˆ†å¸ƒåˆå¹¶æˆæ¡¶
        buckets = bucket_message_counts(message_counts)

        # å®šä¹‰æ¡¶çš„æ˜¾ç¤ºé¡ºåº
        bucket_order = ["1æ¡", "2æ¡", "3-5æ¡", "6-10æ¡", "11-20æ¡",
                       "21-50æ¡", "51-100æ¡", "101-200æ¡", "201-500æ¡", "500+æ¡"]

        # æŒ‰é¡ºåºæ˜¾ç¤ºï¼Œåªæ˜¾ç¤ºæœ‰ç”¨æˆ·çš„æ¡¶
        for bucket_label in bucket_order:
            if bucket_label in buckets:
                user_num = buckets[bucket_label]
                percentage = (user_num / user_count) * 100
                bar = "â–ˆ" * int(percentage / 2)  # ç®€å•çš„æ–‡æœ¬æ¡å½¢å›¾
                print(f"    {bucket_label:>12}: {user_num:>4} ä¸ªç”¨æˆ· ({percentage:>5.1f}%) {bar}")

    print("="*60)


def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python csv_to_json.py <input_csv_file> <output_json_file> [encoding]")
        print("ç¤ºä¾‹: python csv_to_json.py chat_records.csv output.json")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]
    encoding = sys.argv[3] if len(sys.argv) > 3 else 'utf-8-sig'

    try:
        print(f"ğŸ“– æ­£åœ¨è¯»å– CSV æ–‡ä»¶: {input_file}")
        records = read_csv_chat_records(input_file, encoding)
        print(f"âœ… è¯»å–åˆ° {len(records)} æ¡è®°å½•")

        print(f"ğŸ”„ æ­£åœ¨æŒ‰ userId èšåˆæ•°æ®...")
        aggregated = aggregate_by_user_id(records)
        print(f"âœ… èšåˆå®Œæˆ")

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print_statistics(aggregated)

        print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° JSON æ–‡ä»¶: {output_file}")
        save_json(output_file, aggregated)
        print(f"âœ… ä¿å­˜å®Œæˆï¼")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()

