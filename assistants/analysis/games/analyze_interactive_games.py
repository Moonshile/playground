#!/usr/bin/env python3
"""
analyze_interactive_games.py

åŠŸèƒ½ï¼š
åˆ†æJSONæ ¼å¼çš„èŠå¤©å†å²è®°å½•ï¼Œè¯†åˆ«ç”¨æˆ·ä¸AIçš„"äº’åŠ¨æ¸¸æˆ"è¡Œä¸ºã€‚
æ”¯æŒGPTå’ŒGeminiä¸¤ç§æ¨¡å‹è¿›è¡Œåˆ†æã€‚
"""

import sys
import json
import csv
import os
import time
from typing import List, Dict, Any
from openai import OpenAI
import google.genai as genai

ANALYSIS_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŠå¤©è¡Œä¸ºåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·ä¸AIçš„èŠå¤©è®°å½•ï¼Œè¯†åˆ«å…¶ä¸­æ˜¯å¦å­˜åœ¨"äº’åŠ¨æ¸¸æˆ"è¡Œä¸ºã€‚

å®šä¹‰ï¼š
- "äº’åŠ¨æ¸¸æˆ" = ç”¨æˆ·ä¸»åŠ¨æå‡ºç©æ³•/è§„åˆ™/è§’è‰²æ‰®æ¼”/å›åˆæœºåˆ¶/è¡¨æƒ…æˆ–ç¬¦å·çº¦å®š/æƒ…ç»ªæˆ–è¯­æ°”æ¨¡æ‹Ÿ/çŒœè°œç«èµ›ç­‰ã€‚
- éœ€è¦å‡ºç°"å‘èµ·æˆ–é»˜è®¤æ¥å—çš„è§„åˆ™/ç©æ³•"ï¼Œè€Œä¸åªæ˜¯é—²èŠæˆ–æ™®é€šé—®ç­”ã€‚

è¯·ä»”ç»†åˆ†æèŠå¤©è®°å½•ï¼Œè¯†åˆ«æ‰€æœ‰çš„äº’åŠ¨æ¸¸æˆã€‚å¯¹äºæ¯ä¸ªè¯†åˆ«åˆ°çš„æ¸¸æˆï¼Œéœ€è¦æå–ï¼š
1. æ¸¸æˆåç§°
2. æ¸¸æˆè§„åˆ™
3. èŠå¤©å†…å®¹ç¤ºä¾‹ï¼ˆå±•ç¤ºæœ€èƒ½ä½“ç°è¯¥æ¸¸æˆçš„å¯¹è¯ç‰‡æ®µï¼Œ1-3æ¡æ¶ˆæ¯å³å¯ï¼‰

å¦‚æœå­˜åœ¨å¤šä¸ªä¸åŒç±»å‹çš„æ¸¸æˆï¼Œè¯·åˆ†åˆ«åˆ—å‡ºã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{
  "games": [
    {
      "game_name": "æ¸¸æˆåç§°",
      "game_rules": "æ¸¸æˆè§„åˆ™æè¿°",
      "content_example": "èŠå¤©å†…å®¹ç¤ºä¾‹"
    }
  ]
}

å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•äº’åŠ¨æ¸¸æˆï¼Œè¿”å›ï¼š{"games": []}

ç°åœ¨è¯·åˆ†æä»¥ä¸‹èŠå¤©è®°å½•ï¼š

"""


def load_json(input_file, encoding='utf-8'):
    """
    è¯»å– JSON æ–‡ä»¶

    Args:
        input_file (str): è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„
        encoding (str): æ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤: utf-8ï¼‰

    Returns:
        dict: JSON æ•°æ®
    """
    with open(input_file, 'r', encoding=encoding) as f:
        return json.load(f)


def format_chat_history(messages: List[Dict[str, Any]]) -> str:
    """
    å°†èŠå¤©è®°å½•æ ¼å¼åŒ–ä¸ºæ–‡æœ¬

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨

    Returns:
        str: æ ¼å¼åŒ–åçš„èŠå¤©è®°å½•æ–‡æœ¬
    """
    formatted = []
    for msg in messages:
        msg_type = msg.get('type', '')
        content = msg.get('content', '')
        dbctime = msg.get('dbctime', '')

        # type=1 é€šå¸¸æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œtype=40 é€šå¸¸æ˜¯AIå›å¤ï¼ˆæ ¹æ®ç¤ºä¾‹åˆ¤æ–­ï¼‰
        role = "ç”¨æˆ·" if msg_type == "1" else "AI"
        formatted.append(f"[{dbctime}] {role}: {content}")

    return "\n".join(formatted)


def get_chat_time_range(messages: List[Dict[str, Any]]) -> str:
    """
    è·å–èŠå¤©è®°å½•çš„æ—¶é—´èŒƒå›´

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨

    Returns:
        str: æ—¶é—´èŒƒå›´å­—ç¬¦ä¸²
    """
    if not messages:
        return ""

    times = [msg.get('dbctime', '') for msg in messages if msg.get('dbctime')]
    if not times:
        return ""

    times = sorted(times)
    start_time = times[0]
    end_time = times[-1]

    if start_time == end_time:
        return start_time
    return f"{start_time} ~ {end_time}"


def call_gpt_model(client: OpenAI, chat_history: str, model: str = "gpt-4o") -> Dict[str, Any]:
    """
    è°ƒç”¨GPTæ¨¡å‹è¿›è¡Œåˆ†æ

    Args:
        client: OpenAIå®¢æˆ·ç«¯
        chat_history: èŠå¤©å†å²æ–‡æœ¬
        model: æ¨¡å‹åç§°

    Returns:
        dict: è§£æåçš„JSONç»“æœ
    """
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èŠå¤©è¡Œä¸ºåˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"},
        {"role": "user", "content": ANALYSIS_PROMPT + chat_history + "\n\nè¯·åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ã€‚"}
    ]

    # å°è¯•ä½¿ç”¨ response_formatï¼Œå¦‚æœä¸æ”¯æŒåˆ™å¿½ç•¥
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3,
            response_format={"type": "json_object"}
        )
    except Exception:
        # å¦‚æœä¸æ”¯æŒ response_formatï¼Œåˆ™ä½¿ç”¨æ™®é€šè°ƒç”¨
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.3
        )

    result_text = response.choices[0].message.content.strip()

    # å°è¯•æå–JSONï¼ˆå¦‚æœè¿”å›å†…å®¹åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
    if result_text.startswith("```json"):
        result_text = result_text.replace("```json", "").replace("```", "").strip()
    elif result_text.startswith("```"):
        result_text = result_text.replace("```", "").strip()

    return json.loads(result_text)


def call_gemini_model(chat_history: str, model_name: str = "gemini-2.0-flash-exp", api_key: str = None) -> Dict[str, Any]:
    """
    è°ƒç”¨Geminiæ¨¡å‹è¿›è¡Œåˆ†æï¼ˆä½¿ç”¨æœ€æ–°ç‰ˆ google-genai APIï¼‰

    Args:
        chat_history: èŠå¤©å†å²æ–‡æœ¬
        model_name: æ¨¡å‹åç§°
        api_key: Google API å¯†é’¥

    Returns:
        dict: è§£æåçš„JSONç»“æœ
    """
    # ä½¿ç”¨æœ€æ–°çš„ API åˆ›å»ºå®¢æˆ·ç«¯
    client = genai.Client(api_key=api_key) if api_key else genai.Client()
    prompt = ANALYSIS_PROMPT + chat_history + "\n\nè¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œåªè¿”å›JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ã€‚"

    # ä½¿ç”¨æœ€æ–°çš„ API è°ƒç”¨æ–¹å¼
    response = client.models.generate_content(
        model=model_name,
        contents=prompt,
        config={
            "temperature": 0.3,
        }
    )

    # å¤„ç†å“åº”
    if hasattr(response, 'text'):
        result_text = response.text.strip()
    elif hasattr(response, 'candidates') and len(response.candidates) > 0:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä» candidates è·å–
        candidate = response.candidates[0]
        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
            result_text = candidate.content.parts[0].text.strip()
        else:
            raise ValueError("æ— æ³•ä»å“åº”ä¸­è·å–æ–‡æœ¬å†…å®¹")
    else:
        raise ValueError("æ— æ³•ä»å“åº”ä¸­è·å–æ–‡æœ¬å†…å®¹")

    # å°è¯•æå–JSONï¼ˆå¦‚æœè¿”å›å†…å®¹åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
    if result_text.startswith("```json"):
        result_text = result_text.replace("```json", "").replace("```", "").strip()
    elif result_text.startswith("```"):
        result_text = result_text.replace("```", "").strip()

    return json.loads(result_text)


def analyze_user_chat(user_id: str, messages: List[Dict[str, Any]],
                     model_type: str, model_name: str) -> List[Dict[str, Any]]:
    """
    åˆ†æå•ä¸ªç”¨æˆ·çš„èŠå¤©è®°å½•

    Args:
        user_id: ç”¨æˆ·ID
        messages: æ¶ˆæ¯åˆ—è¡¨
        model_type: æ¨¡å‹ç±»å‹ ("gpt" æˆ– "gemini")
        model_name: å…·ä½“çš„æ¨¡å‹åç§°

    Returns:
        list: è¯†åˆ«åˆ°çš„æ¸¸æˆåˆ—è¡¨ï¼Œæ¯ä¸ªæ¸¸æˆæ˜¯ä¸€ä¸ªå­—å…¸
    """
    if not messages:
        return []

    chat_history = format_chat_history(messages)

    try:
        if model_type.lower() == "gpt":
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            if not client.api_key:
                raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            result = call_gpt_model(client, chat_history, model_name)
        elif model_type.lower() == "gemini":
            api_key = os.getenv("GOOGLE_API_KEY")
            if not api_key:
                raise ValueError("è¯·è®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡")
            result = call_gemini_model(chat_history, model_name, api_key)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}ï¼Œè¯·ä½¿ç”¨ 'gpt' æˆ– 'gemini'")

        games = result.get("games", [])
        if not isinstance(games, list):
            games = []

        return games

    except json.JSONDecodeError as e:
        print(f"  âš ï¸  ç”¨æˆ· {user_id} çš„è¿”å›ç»“æœJSONè§£æå¤±è´¥: {str(e)}")
        return []
    except Exception as e:
        print(f"  âš ï¸  ç”¨æˆ· {user_id} åˆ†æå¤±è´¥: {str(e)}")
        return []


def save_results_to_csv(output_file: str, results: List[Dict[str, Any]], encoding='utf-8', append=False):
    """
    ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶

    Args:
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        results: ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼šåºå·ã€ç”¨æˆ·IDã€èŠå¤©è®°å½•æ—¶é—´ã€æ¸¸æˆåç§°ã€æ¸¸æˆè§„åˆ™ã€èŠå¤©å†…å®¹ç¤ºä¾‹ã€èŠå¤©è®°å½•
        encoding: æ–‡ä»¶ç¼–ç 
        append: æ˜¯å¦è¿½åŠ æ¨¡å¼ï¼ˆå¦‚æœä¸ºTrueï¼Œä¸”æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™è¿½åŠ æ•°æ®ï¼›å¦åˆ™å†™å…¥è¡¨å¤´ï¼‰
    """
    file_exists = os.path.exists(output_file) and os.path.getsize(output_file) > 0

    mode = 'a' if append and file_exists else 'w'
    with open(output_file, mode, newline='', encoding=encoding) as f:
        writer = csv.writer(f)

        # å¦‚æœä¸æ˜¯è¿½åŠ æ¨¡å¼æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´
        if not (append and file_exists):
            writer.writerow(['åºå·', 'ç”¨æˆ·ID', 'èŠå¤©è®°å½•æ—¶é—´', 'æ¸¸æˆåç§°', 'æ¸¸æˆè§„åˆ™', 'èŠå¤©å†…å®¹ç¤ºä¾‹', 'èŠå¤©è®°å½•'])

        # å†™å…¥æ•°æ®
        for row in results:
            writer.writerow([
                row['åºå·'],
                row['ç”¨æˆ·ID'],
                row['èŠå¤©è®°å½•æ—¶é—´'],
                row['æ¸¸æˆåç§°'],
                row['æ¸¸æˆè§„åˆ™'],
                row['èŠå¤©å†…å®¹ç¤ºä¾‹'],
                row.get('èŠå¤©è®°å½•', '')
            ])


def generate_chat_link(user_id: str) -> str:
    """
    æ ¹æ®ç”¨æˆ·IDç”ŸæˆèŠå¤©è®°å½•é“¾æ¥

    Args:
        user_id: ç”¨æˆ·ID

    Returns:
        str: èŠå¤©è®°å½•é“¾æ¥
    """
    return f"https://assistants.classup.info/tower?userId={user_id}"


def read_existing_csv(output_file: str, encoding='utf-8') -> tuple[int, set[str]]:
    """
    è¯»å–å·²å­˜åœ¨çš„CSVæ–‡ä»¶ï¼Œè·å–å½“å‰åºå·å’Œå·²å¤„ç†çš„ç”¨æˆ·IDé›†åˆ

    Args:
        output_file: CSVæ–‡ä»¶è·¯å¾„
        encoding: æ–‡ä»¶ç¼–ç 

    Returns:
        tuple: (å½“å‰æœ€å¤§åºå·, å·²å¤„ç†çš„ç”¨æˆ·IDé›†åˆ)
    """
    if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:
        return 0, set()

    max_count = 0
    processed_users = set()

    try:
        with open(output_file, 'r', encoding=encoding, newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    count = int(row.get('åºå·', 0))
                    max_count = max(max_count, count)
                    user_id = row.get('ç”¨æˆ·ID', '')
                    if user_id:
                        processed_users.add(user_id)
                except (ValueError, KeyError):
                    continue
    except Exception as e:
        print(f"âš ï¸  è¯»å–å·²æœ‰CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return 0, set()

    return max_count, processed_users


def append_result_to_csv(output_file: str, row_data: Dict[str, Any], current_count: int, encoding='utf-8'):
    """
    è¿½åŠ å•æ¡ç»“æœåˆ°CSVæ–‡ä»¶

    Args:
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        row_data: å•æ¡ç»“æœæ•°æ®
        current_count: å½“å‰åºå·
        encoding: æ–‡ä»¶ç¼–ç 
    """
    file_exists = os.path.exists(output_file) and os.path.getsize(output_file) > 0

    with open(output_file, 'a', newline='', encoding=encoding) as f:
        writer = csv.writer(f)

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆå†™å…¥è¡¨å¤´
        if not file_exists:
            writer.writerow(['åºå·', 'ç”¨æˆ·ID', 'èŠå¤©è®°å½•æ—¶é—´', 'æ¸¸æˆåç§°', 'æ¸¸æˆè§„åˆ™', 'èŠå¤©å†…å®¹ç¤ºä¾‹', 'èŠå¤©è®°å½•'])

        # å†™å…¥æ•°æ®
        writer.writerow([
            current_count,
            row_data['ç”¨æˆ·ID'],
            row_data['èŠå¤©è®°å½•æ—¶é—´'],
            row_data['æ¸¸æˆåç§°'],
            row_data['æ¸¸æˆè§„åˆ™'],
            row_data['èŠå¤©å†…å®¹ç¤ºä¾‹'],
            row_data.get('èŠå¤©è®°å½•', '')
        ])


def main():
    if len(sys.argv) < 5:
        print("ç”¨æ³•: python analyze_interactive_games.py <input_json_file> <output_csv_file> <model_type> <model_name> [min_message_count] [start_user_id] [encoding]")
        print("å‚æ•°è¯´æ˜:")
        print("  input_json_file: è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„")
        print("  output_csv_file: è¾“å‡ºçš„CSVæ–‡ä»¶è·¯å¾„")
        print("  model_type: æ¨¡å‹ç±»å‹ (gpt æˆ– gemini)")
        print("  model_name: æ¨¡å‹åç§° (å¦‚ gpt-4o, gemini-2.0-flash-exp ç­‰)")
        print("  min_message_count: å¯é€‰ï¼Œæœ€å°æ¶ˆæ¯æ•°é‡é˜ˆå€¼ï¼ˆé»˜è®¤: 0ï¼Œå³åˆ†ææ‰€æœ‰ç”¨æˆ·ï¼‰")
        print("  start_user_id: å¯é€‰ï¼Œä»æŒ‡å®šç”¨æˆ·IDå¼€å§‹ç»§ç»­åˆ†æï¼ˆå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨ç»§ç»­ï¼‰")
        print("  encoding: å¯é€‰ï¼Œæ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤: utf-8ï¼‰")
        print("\nç¤ºä¾‹:")
        print("  python analyze_interactive_games.py data.json output.csv gpt gpt-4o")
        print("  python analyze_interactive_games.py data.json output.csv gemini gemini-pro 10")
        print("  python analyze_interactive_games.py data.json output.csv gemini gemini-pro 10 845810418")
        print("  python analyze_interactive_games.py data.json output.csv gemini gemini-pro 10 845810418 utf-8")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]
    model_type = sys.argv[3]
    model_name = sys.argv[4]

    # è§£æå¯é€‰å‚æ•°
    min_message_count = 0
    start_user_id = None
    encoding = 'utf-8'

    # å‚æ•°è§£æï¼šæŒ‰ä½ç½®è§£æ
    if len(sys.argv) > 5:
        arg5 = sys.argv[5]
        try:
            min_message_count = int(arg5)
        except ValueError:
            # ç¬¬5ä¸ªå‚æ•°ä¸æ˜¯æ•°å­—ï¼Œå¯èƒ½æ˜¯ç”¨æˆ·IDæˆ–ç¼–ç 
            if arg5.isdigit():
                start_user_id = arg5
            else:
                encoding = arg5

    if len(sys.argv) > 6:
        arg6 = sys.argv[6]
        if start_user_id is None:
            # å¦‚æœç¬¬5ä¸ªå‚æ•°æ˜¯æ•°å­—ï¼ˆæœ€å°æ¶ˆæ¯æ•°ï¼‰ï¼Œç¬¬6ä¸ªå‚æ•°å°±æ˜¯ç”¨æˆ·IDæˆ–ç¼–ç 
            if arg6.isdigit():
                start_user_id = arg6
            else:
                encoding = arg6
        else:
            # å¦‚æœç¬¬5ä¸ªå‚æ•°å·²ç»æ˜¯ç”¨æˆ·IDï¼Œç¬¬6ä¸ªå‚æ•°å°±æ˜¯ç¼–ç 
            encoding = arg6

    if len(sys.argv) > 7:
        encoding = sys.argv[7]

    if model_type.lower() not in ['gpt', 'gemini']:
        print(f"âŒ é”™è¯¯: ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹ '{model_type}'ï¼Œè¯·ä½¿ç”¨ 'gpt' æˆ– 'gemini'")
        sys.exit(1)

    try:
        print(f"ğŸ“– æ­£åœ¨è¯»å– JSON æ–‡ä»¶: {input_file}")
        data = load_json(input_file, encoding)
        total_users = len(data)
        print(f"âœ… è¯»å–å®Œæˆï¼Œå…± {total_users} ä¸ªç”¨æˆ·")

        # æ ¹æ®æœ€å°æ¶ˆæ¯æ•°é‡è¿‡æ»¤ç”¨æˆ·
        if min_message_count > 0:
            filtered_data = {uid: msgs for uid, msgs in data.items() if len(msgs) >= min_message_count}
            filtered_count = len(filtered_data)
            print(f"ğŸ” è¿‡æ»¤æ¡ä»¶: æ¶ˆæ¯æ•°é‡ >= {min_message_count}")
            print(f"ğŸ“Š è¿‡æ»¤åç”¨æˆ·æ•°: {filtered_count} (ä¿ç•™ {filtered_count/total_users*100:.1f}%)")
            data = filtered_data
        else:
            print(f"ğŸ“Š å°†åˆ†ææ‰€æœ‰ {total_users} ä¸ªç”¨æˆ·")

        if not data:
            print("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç”¨æˆ·éœ€è¦åˆ†æ")
            sys.exit(0)

        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_type} ({model_name})")

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œè¯»å–å·²æœ‰æ•°æ®
        existing_count, processed_users = read_existing_csv(output_file, encoding)
        resume_mode = False

        if os.path.exists(output_file) and existing_count > 0:
            print(f"ğŸ“„ æ£€æµ‹åˆ°å·²æœ‰è¾“å‡ºæ–‡ä»¶ï¼Œå½“å‰åºå·: {existing_count}ï¼Œå·²å¤„ç†ç”¨æˆ·æ•°: {len(processed_users)}")
            if start_user_id:
                print(f"ğŸ¯ å°†ä»ç”¨æˆ·ID '{start_user_id}' å¼€å§‹ç»§ç»­åˆ†æ")
                resume_mode = True
            elif len(processed_users) > 0:
                print(f"ğŸ”„ å°†è·³è¿‡å·²å¤„ç†çš„ç”¨æˆ·ï¼Œç»§ç»­è¿½åŠ ç»“æœ")
                resume_mode = True

        # å¦‚æœæŒ‡å®šäº†èµ·å§‹ç”¨æˆ·IDï¼Œä»è¯¥ç”¨æˆ·å¼€å§‹
        if start_user_id and start_user_id not in data:
            print(f"âŒ é”™è¯¯: æŒ‡å®šçš„èµ·å§‹ç”¨æˆ·ID '{start_user_id}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
            sys.exit(1)

        # è¿‡æ»¤éœ€è¦å¤„ç†çš„ç”¨æˆ·
        users_to_process = []
        skip_count = 0
        start_idx = None

        for idx, (user_id, messages) in enumerate(data.items(), 1):
            # å¦‚æœæŒ‡å®šäº†èµ·å§‹ç”¨æˆ·IDï¼Œæ‰¾åˆ°è¯¥ç”¨æˆ·çš„ä½ç½®
            if start_user_id and user_id == start_user_id:
                start_idx = idx
                users_to_process.append((idx, user_id, messages))
            elif start_user_id and start_idx is None:
                continue  # è¿˜æ²¡æ‰¾åˆ°èµ·å§‹ç”¨æˆ·ï¼Œç»§ç»­è·³è¿‡
            elif start_idx is not None:
                # å·²ç»è¿‡äº†èµ·å§‹ç”¨æˆ·ï¼ŒåŠ å…¥å¤„ç†åˆ—è¡¨
                users_to_process.append((idx, user_id, messages))
            elif start_user_id is None and resume_mode:
                # å¦‚æœæ²¡æœ‰æŒ‡å®šèµ·å§‹ç”¨æˆ·ä½†æ–‡ä»¶å­˜åœ¨ï¼Œè·³è¿‡å·²å¤„ç†çš„ç”¨æˆ·
                if user_id in processed_users:
                    skip_count += 1
                    continue
                users_to_process.append((idx, user_id, messages))
            elif start_user_id is None and not resume_mode:
                # å…¨æ–°å¼€å§‹
                users_to_process.append((idx, user_id, messages))

        if skip_count > 0:
            print(f"â­ï¸  è·³è¿‡å·²å¤„ç†çš„ç”¨æˆ·: {skip_count} ä¸ª")

        if not users_to_process:
            print("âœ… æ‰€æœ‰ç”¨æˆ·éƒ½å·²å¤„ç†å®Œæˆï¼Œæ— éœ€ç»§ç»­åˆ†æ")
            sys.exit(0)

        print(f"ğŸ“Š å¾…å¤„ç†ç”¨æˆ·æ•°: {len(users_to_process)}")
        print(f"\nğŸ”„ å¼€å§‹åˆ†æ...\n")

        total_results = existing_count
        processed = 0
        start_time = time.time()
        user_count_with_games = set(processed_users)  # åŒ…å«å·²å¤„ç†çš„ç”¨æˆ·

        for idx, user_id, messages in users_to_process:
            print(f"[{idx}/{len(data)}] æ­£åœ¨åˆ†æç”¨æˆ· {user_id} (æ¶ˆæ¯æ•°: {len(messages)})...", end=" ")

            chat_time = get_chat_time_range(messages)
            games = analyze_user_chat(user_id, messages, model_type, model_name)

            if games:
                print(f"âœ… è¯†åˆ«åˆ° {len(games)} ä¸ªæ¸¸æˆ")
                user_count_with_games.add(user_id)

                # ç”ŸæˆèŠå¤©è®°å½•é“¾æ¥
                chat_link = generate_chat_link(user_id)

                # æ¯è¯†åˆ«åˆ°ä¸€ä¸ªæ¸¸æˆå°±ç«‹å³ä¿å­˜
                for game in games:
                    total_results += 1
                    row_data = {
                        'ç”¨æˆ·ID': user_id,
                        'èŠå¤©è®°å½•æ—¶é—´': chat_time,
                        'æ¸¸æˆåç§°': game.get('game_name', ''),
                        'æ¸¸æˆè§„åˆ™': game.get('game_rules', ''),
                        'èŠå¤©å†…å®¹ç¤ºä¾‹': game.get('content_example', ''),
                        'èŠå¤©è®°å½•': chat_link
                    }
                    append_result_to_csv(output_file, row_data, total_results, encoding)
            else:
                print("æœªè¯†åˆ«åˆ°æ¸¸æˆ")

            processed += 1

            # æ˜¾ç¤ºè¿›åº¦
            if processed % 10 == 0:
                elapsed = time.time() - start_time
                avg_time = elapsed / processed if processed > 0 else 0
                remaining_users = len(users_to_process) - processed
                remaining = remaining_users * avg_time
                print(f"\n   è¿›åº¦: {processed}/{len(users_to_process)} ({processed/len(users_to_process)*100:.1f}%), "
                      f"é¢„è®¡å‰©ä½™æ—¶é—´: {remaining/60:.1f} åˆ†é’Ÿ, "
                      f"å·²è¯†åˆ«æ¸¸æˆæ•°: {total_results}\n")

            # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
            time.sleep(0.5)

        elapsed = time.time() - start_time
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"   æ€»è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
        print(f"   å·²åˆ†æç”¨æˆ·æ•°: {processed}")
        print(f"   è¯†åˆ«åˆ°æ¸¸æˆæ•°é‡: {total_results}")
        print(f"   æ¶‰åŠç”¨æˆ·æ•°: {len(user_count_with_games)}")
        print(f"   ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"âŒ é”™è¯¯: JSON è§£æå¤±è´¥: {str(e)}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

