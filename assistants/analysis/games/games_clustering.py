#!/usr/bin/env python3
"""
games_clustering.py

åŠŸèƒ½ï¼š
å¯¹æ¸¸æˆæ•°æ®è¿›è¡Œèšç±»åˆ†æï¼Œå°†ç›¸ä¼¼çš„æ¸¸æˆå½’ç±»åˆ°ä¸€èµ·ã€‚
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import numpy as np
import sys
import pandas as pd
import os


def main():
    if len(sys.argv) < 4:
        print("ç”¨æ³•: python games_clustering.py <input_csv_file> <output_csv_file> <n_clusters> [encoding]")
        print("å‚æ•°è¯´æ˜:")
        print("  input_csv_file: è¾“å…¥çš„CSVæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«æ¸¸æˆåç§°ã€æ¸¸æˆè§„åˆ™ç­‰åˆ—ï¼‰")
        print("  output_csv_file: è¾“å‡ºçš„CSVæ–‡ä»¶è·¯å¾„")
        print("  n_clusters: èšç±»ç±»åˆ«æ•°é‡ï¼ˆæ•´æ•°ï¼‰")
        print("  encoding: å¯é€‰ï¼Œæ–‡ä»¶ç¼–ç ï¼ˆé»˜è®¤: utf-8ï¼‰")
        print("\nç¤ºä¾‹:")
        print("  python games_clustering.py input.csv output.csv 10")
        print("  python games_clustering.py input.csv output.csv 15 utf-8")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]

    try:
        n_clusters = int(sys.argv[3])
        if n_clusters <= 0:
            print("âŒ é”™è¯¯: ç±»åˆ«æ•°é‡å¿…é¡»å¤§äº0")
            sys.exit(1)
    except ValueError:
        print("âŒ é”™è¯¯: ç±»åˆ«æ•°é‡å¿…é¡»æ˜¯æ•´æ•°")
        sys.exit(1)

    encoding = sys.argv[4] if len(sys.argv) > 4 else 'utf-8'

    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_file):
            print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            sys.exit(1)

        print(f"ğŸ“– æ­£åœ¨è¯»å–è¾“å…¥æ–‡ä»¶: {input_file}")
        df = pd.read_csv(input_file, encoding=encoding)
        print(f"âœ… è¯»å–å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")

        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ["æ¸¸æˆåç§°", "æ¸¸æˆè§„åˆ™"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_columns)}")
            sys.exit(1)

        print(f"ğŸ”„ æ­£åœ¨è¿›è¡Œèšç±»åˆ†æï¼ˆç±»åˆ«æ•°: {n_clusters}ï¼‰...")

        # ä½¿ç”¨æ¸¸æˆè§„åˆ™å’Œåç§°ä½œä¸ºæ–‡æœ¬ç‰¹å¾
        texts = df["æ¸¸æˆåç§°"].astype(str) + " " + df["æ¸¸æˆè§„åˆ™"].astype(str)

        # æå–æ–‡æœ¬ç‰¹å¾
        vectorizer = TfidfVectorizer(max_features=500, stop_words=None)
        X = vectorizer.fit_transform(texts)

        # ä½¿ç”¨ KMeans èšç±»è‡ªåŠ¨å½’ç±»æ¸¸æˆ
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = kmeans.fit_predict(X)
        df["æ¸¸æˆç±»åˆ«ID"] = labels

        print(f"âœ… èšç±»å®Œæˆï¼Œå…±ç”Ÿæˆ {len(set(labels))} ä¸ªç±»åˆ«")

        # èšåˆåŒä¸€ç±»åˆ«çš„æ ·æœ¬
        grouped_rows = []
        for label in sorted(df["æ¸¸æˆç±»åˆ«ID"].unique()):
            subset = df[df["æ¸¸æˆç±»åˆ«ID"] == label]
            category_name = subset["æ¸¸æˆåç§°"].mode()[0] if not subset["æ¸¸æˆåç§°"].mode().empty else f"ç±»åˆ«{label}"
            rule_summary = subset["æ¸¸æˆè§„åˆ™"].iloc[0]

            # ç”¨æˆ·åˆ—è¡¨ç¤ºä¾‹ï¼ˆæœ€å¤š10ä¸ªç”¨æˆ·é“¾æ¥ï¼‰
            user_links = []
            if "èŠå¤©è®°å½•" in subset.columns:
                user_links = subset["èŠå¤©è®°å½•"].tolist()
            # é™åˆ¶æœ€å¤š10ä¸ªç”¨æˆ·é“¾æ¥
            max_user_links = 10
            user_links = user_links[:max_user_links]
            user_list_sample = "\n".join(user_links)
            # å¦‚æœåŸå§‹é“¾æ¥æ•°é‡è¶…è¿‡é™åˆ¶ï¼Œæ·»åŠ æç¤º
            if "èŠå¤©è®°å½•" in subset.columns and len(subset["èŠå¤©è®°å½•"].tolist()) > max_user_links:
                user_list_sample += f"\n(å…±{len(subset)}ä¸ªç”¨æˆ·ï¼Œä»…æ˜¾ç¤ºå‰{max_user_links}ä¸ª)"

            # å¯¹è¯ç¤ºä¾‹ï¼ˆä¸åŒç”¨æˆ·ä¹‹é—´ç”¨ --- åˆ†éš”ï¼‰
            dialogs = []
            if "èŠå¤©å†…å®¹ç¤ºä¾‹" in subset.columns:
                dialogs = subset["èŠå¤©å†…å®¹ç¤ºä¾‹"].tolist()
            dialog_sample = "\n---\n".join(dialogs[:10])  # æœ€å¤š10ä¸ªæ ·æœ¬

            grouped_rows.append({
                "æ¸¸æˆç±»åˆ«": category_name,
                "ç©æ³•è§„åˆ™": rule_summary,
                "ç”¨æˆ·åˆ—è¡¨ç¤ºä¾‹": user_list_sample,
                "å¯¹è¯ç¤ºä¾‹": dialog_sample,
                "æ ·æœ¬æ•°é‡": len(subset)
            })

        # æ„é€ ç»“æœ DataFrame
        result_df = pd.DataFrame(grouped_rows)

        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ°: {output_file}")
        result_df.to_csv(output_file, index=False, encoding=encoding)

        print(f"âœ… å®Œæˆï¼")
        print(f"   è¾“å…¥è®°å½•æ•°: {len(df)}")
        print(f"   èšç±»ç±»åˆ«æ•°: {len(result_df)}")
        print(f"   ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
